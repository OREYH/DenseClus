{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the Validation of HDBSCAN\n",
    "\n",
    "\n",
    "Clustering is a very hard problem because there is never truly a 'right' answer when labels do not exist.\n",
    "\n",
    "This is compounded by techniques with various assumptions in place. If a technique is run incorrectly, violating an assumption, this leads to incorrect (dead wrong) results.\n",
    "\n",
    "In this blogpost, we will delve a bit into why clustering gets complicated, and then take a dive deep on how to properly tune density-based clusters in [HDBSCAN](https://github.com/scikit-learn-contrib/hdbscan).\n",
    "\n",
    "\n",
    "## Background: Clustering is Complicated\n",
    "\n",
    "There is [No Free Lunch](https://en.wikipedia.org/wiki/No_free_lunch_theorem) for clustering algorithms and while one algorithm might fit a certain dataset well, there are no guarantees that it will work on a different dataset in the exact same manner. Likewise, clustering is \"strongly dependent on contexts, aims and decisions of the researcher\" which adds fire to the argument that there is no such thing as a \"universally optimal method that will just produce natural clusters\" as noted by Henning in [What Are True Clusters? Henning 2015](https://arxiv.org/abs/1502.02555).\n",
    "\n",
    "For example, commonly used techniques such as KMeans, assume that data is numerical and sphere-shaped. Those types of assumptions do not fair well when the data has high dimensionality and includes categorical values. \n",
    "\n",
    "Cluster data that is in violation of assumptions causes a conundrum for the practitioner in two ways: \n",
    "\n",
    "1) How to formalize a specific featurization scheme?\n",
    "2) What clustering technique to choose? \n",
    "\n",
    "Both of these must be formulated so that no assumptions are violated. In practice,  this can lead to a process of elimination whereby the algorithm and featurization scheme that don’t violate an algorithm's assumptions is the only choice standing.\n",
    "\n",
    "## Be Wary of Your Metric\n",
    "\n",
    "When no labels are available it's common to pick a objective metric such as [Silhouette Score](https://en.wikipedia.org/wiki/Silhouette_(clustering)) to evaluate and then decide on the final clustering result. Silhouette Score measures cluster cohesiveness and separation with an index between -1 to 1. It does *NOT* take into account noise in the index calculation and makes use of distances. Distance is not applicable for a density-based technique. Not including a noise in the objective metric calculation violates an inherent assumption in density-based clustering.\n",
    "\n",
    "**This means that Silhouette Score and similar indexes like it are inappropriate for measuring density-based techniques!!!**\n",
    "(my own emphasis added because I've seen multiple blogs on here doing it - this is dangerous.)\n",
    "\n",
    "\n",
    "## Density Based Clustering Validation to the Rescue\n",
    "\n",
    "Density Based Clustering Validation or DBCV works for desnity-based clustering algorithms precisely because it takes noise into account and captures the shape property of clusters via densities and not distances (see the [original paper](https://www.dbs.ifi.lmu.de/~zimek/publications/SDM2014/DBCV.pdf))\n",
    "\n",
    "As the paper explains, the final result of DBCV is a weighted sum of “Validity Index” values of clusters. This produces a score between -1 to 1, with the larger the value the better clustering solution.\n",
    "\n",
    "Source: Density-Based Clustering Validation, Moulavi et al. 2014\n",
    "\n",
    "An in depth discussion is out scope here but please see the original paper for more details.\n",
    "\n",
    "Note that DBCV does have [drawbacks](https://github.com/scikit-learn-contrib/hdbscan/issues/283). Like all other metrics and techniques DBCV is not immune from the problems of complication and measurement in clustering as noted earlier.\n",
    "\n",
    "However, outside of having groundtruth labels it provides an objective criteria from which to judge how well-separated density-based technique clusters are.\n",
    "\n",
    "## Example\n",
    "\n",
    "Enough of that, let's dive into a real example. \n",
    "\n",
    "The [notebook](https://github.com/awslabs/amazon-denseclus/blob/main/notebooks/Tuning%20with%20HDBSCAN.ipynb) is available within the [Amazon Denseclus library](https://github.com/awslabs/amazon-denseclus).\n",
    "\n",
    "In this example, you will use a synthetic churn dataset for an imaginary telecommunications company with the outcome Churn? flagged as as either True (churned) or False (did not churn). Features include customer details such as plan and usage information. The churn dataset is publicly available and mentioned in the book [Discovering Knowledge in Data by Daniel T. Larose](https://www.amazon.com/dp/0470908742/). It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets.\n",
    "\n",
    "The data includes both numeric and categorical features but will use Denseclus to transform it into lower-dimensional, dense space to form clusters on. For more DenseClus [see here](https://aws.amazon.com/blogs/opensource/introducing-denseclus-an-open-source-clustering-package-for-mixed-type-data/). All of the need transformations are taken care of under the hood. You just get to call `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  # to further silence deprecation warnings\n",
    "import warnings\n",
    "\n",
    "import hdbscan\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# This runs in about a minute or two\n",
    "from denseclus import DenseClus\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set(rc={\"figure.figsize\": (10, 8)})\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)  # set the random seed as best we can\n",
    "\n",
    "data_url = (\n",
    "    \"https://raw.githubusercontent.com/awslabs/aws-customer-churn-pipeline/main/data/churn.txt\"\n",
    ")\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "df.drop([\"Phone\", \"Area Code\"], axis=1, inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.captureWarnings(True)\n",
    "clf = DenseClus(random_state=SEED, umap_combine_method=\"intersection_union_mapper\")\n",
    "\n",
    "clf.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, among other steps, Denseclus uses HDBSCAN to cluster the data.\n",
    "\n",
    "Let's look at the how the data got split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = clf.mapper_.embedding_\n",
    "labels = clf.score()\n",
    "clustered = labels >= 0\n",
    "\n",
    "cnts = pd.DataFrame(labels)[0].value_counts()\n",
    "cnts = cnts.reset_index()\n",
    "cnts.columns = [\"cluster\", \"count\"]\n",
    "print(cnts.sort_values([\"cluster\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examination there are exactly 4 almost evenly distributed clusters with -1 representing the noise found in the data.\n",
    "\n",
    "In addition, to simply looking at their spread, another way to evaluate clusters it to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.jointplot(\n",
    "    x=embedding[clustered, 0], y=embedding[clustered, 1], hue=labels[clustered], kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have 4 distinct islands formed within this slice of the data. Clusters have formed around these densities which is exactly the behavior we expect DenseClus to do.\n",
    "\n",
    "You can further confirm the outcome by plotting the tree along which the densities were split.\n",
    "\n",
    "This is a graphical view of the counts we saw with more information. For example, you can see that a two cluster solution is also possible as two densities represent the base split for the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = clf.hdbscan_.condensed_tree_.plot(\n",
    "    select_clusters=True,\n",
    "    selection_palette=sns.color_palette(\"deep\", np.unique(clusters).shape[0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's confirm that the majority of data points are covered by our clusters (hint: only 9 aren't) and the DBCV score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = np.sum(clustered) / embedding.shape[0]\n",
    "\n",
    "print(f\"Coverage {coverage}\")\n",
    "print(f\"DBCV score {clf.hdbscan_.relative_validity_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBCV comes out to 0.28 on scale of -1 to 1. \n",
    "\n",
    "That's not great but it could be worse. Let's optimize the score to find the best HDBSCAN hyperparameters to pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "The two primary hyperparameters to look at to further improve results are `min_samples` and `min_cluster_size`, as noted in the [HDBSCAN documentation](https://hdbscan.readthedocs.io/en/latest/parameter_selection.html).\n",
    "\n",
    "You will run multiple combinations of these to find a result that generates high DBCV score.\n",
    "\n",
    "In addition to looking at these hyperparameters you will also look at cluster selection methods with Expectation of Mass eom and splitting clusters along the tree with leaf (for details see hdbscan: Hierarchical density based clustering In, McInnes, J. Healy, S. Astels 2017).\n",
    "\n",
    "As HDBSCAN's documentation notes, whereas the eom method only extracts the most stable, condensed clusters from the tree, the leaf method selects clusters from the bottom of the leaf nodes as well.\n",
    "\n",
    "This results in smaller, more homogeneous clusters that are more likely to be fine grained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.captureWarnings(True)\n",
    "hdb = hdbscan.HDBSCAN(gen_min_span_tree=True).fit(embedding)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "    \"min_samples\": [10, 30, 50, 60, 100],\n",
    "    \"min_cluster_size\": [100, 200, 300, 400, 500, 600],\n",
    "    \"cluster_selection_method\": [\"eom\", \"leaf\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "}\n",
    "\n",
    "# validity_scroer = \"hdbscan__hdbscan___HDBSCAN__validity_index\"\n",
    "validity_scorer = make_scorer(hdbscan.validity.validity_index, greater_is_better=True)\n",
    "\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(\n",
    "    hdb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter_search,\n",
    "    scoring=validity_scorer,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "random_search.fit(embedding)\n",
    "\n",
    "\n",
    "print(f\"Best Parameters {random_search.best_params_}\")\n",
    "print(f\"DBCV score :{random_search.best_estimator_.relative_validity_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBCV score has now risen from 0.28 to 0.488.\n",
    "\n",
    "DenseClus defaults `min_samples` at 15 and `min_cluster_size` at 100.\n",
    "Random Search results have clusters larger and more restrictive, which results in a higher density and higher score :) City-block distance or Manhattan distance appears to aid the increase too.\n",
    "\n",
    "In practice we would want a score over 0.45 to make sure that clusters are well-separated and this score shows that.\n",
    "\n",
    "Let's confirm this by looking at how clusters were split and visualizing the results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalute the clusters\n",
    "labels = random_search.best_estimator_.labels_\n",
    "clustered = labels >= 0\n",
    "\n",
    "coverage = np.sum(clustered) / embedding.shape[0]\n",
    "total_clusters = np.max(labels) + 1\n",
    "cluster_sizes = np.bincount(labels[clustered]).tolist()\n",
    "\n",
    "print(f\"Percent of data retained: {coverage}\")\n",
    "print(f\"Total Clusters found: {total_clusters}\")\n",
    "print(f\"Cluster splits: {cluster_sizes}\")\n",
    "\n",
    "\n",
    "_ = sns.jointplot(\n",
    "    x=embedding[clustered, 0], y=embedding[clustered, 1], hue=labels[clustered], kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, enough no noise was found. Two clusters are the exact same, with one almost their combined size.\n",
    "\n",
    "Visualizing the data on the same slice gives us a clue as to what happened here. The clusters numbered 3 and 2 from our previous run are now combined.\n",
    "\n",
    "Shifting to a different dimensional slice can sometimes help explain things here and the below plot shows a better view.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.jointplot(\n",
    "    x=embedding[clustered, 1], y=embedding[clustered, 2], hue=labels[clustered], kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I hoped you enjoyed a closer look at how to tune hyperparameters for HDBSCAN!!!\n",
    "\n",
    "In this post you looked at why clustering and clustering metrics can get complicated, you then learned about DBCV as an objective metric, and you then applied it using Amazon Denseclus and HDBSCAN.\n",
    "\n",
    "We've only scrapped the surface here. To dive deeper you could look at the following:\n",
    "\n",
    "* What other type of optimization frameworks can you use in place of Random Search?\n",
    "* What other type of hyperparameters are possible to use for tuning?\n",
    "* What other measures are possible here for further cluster validation?\n",
    "* Can any other underlying hyperparameters in Denseclus be tweaked to achieve a higher score?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\"Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis\", Rousseeuw 1987\n",
    "\n",
    "\"Density-Based Clustering Validation\", Moulavi et al. 2014\n",
    "\n",
    "\"hdbscan: Hierarchical density based clustering In\", McInnes, J. Healy, S. Astels 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DensityClustering",
   "language": "python",
   "name": "denseclus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
