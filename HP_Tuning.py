#!/usr/bin/env python3
"""tune_denseclus.py
-------------------------------------------------------
UMAP + HDBSCAN í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ (ì¬í˜„ì„± ê°•í™” ë²„ì „)
 - YAML ì €ì¥
 - ê²°ê³¼ ë¡œê·¸ëŠ” results í´ë”ì—, YAML íŒŒì¼ì€ yaml í´ë”ì— ì €ì¥
 - `set_global_seed()` ë¡œ NumPyÂ·randomÂ·PYTHONHASHSEED ëª¨ë‘ ê³ ì • â†’ ë°˜ë³µ ì‹¤í–‰ ì‹œ
   ë™ì¼í•œ coverage / DBCV ë³´ì¥
-------------------------------------------------------
ì‚¬ìš© ì˜ˆ)
    python tune_denseclus.py \
        --data_path ./data/train.csv \
        --save_name best_denseclus \
        --sample 20000 \
        --seed 42
    # ê²°ê³¼ íŒŒì¼ì€ yaml/best_denseclus_<ë‚ ì§œì‹œê°„>.yaml, 
    # ë¡œê·¸ íŒŒì¼ì€ results/best_denseclus_<ë‚ ì§œì‹œê°„>.log ë¡œ ì €ì¥
"""

import os
import argparse
import warnings
import random
from itertools import product
import logging
from datetime import datetime

import numpy as np
import pandas as pd
import yaml
from tqdm import tqdm

from denseclus import DenseClus

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ê³  ì–µì œ (sklearn force_all_finite)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings(
    "ignore", category=FutureWarning, message=".*force_all_finite.*"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œë“œ ê³ ì • ìœ í‹¸ë¦¬í‹° (ì¬í˜„ì„± í™•ë³´)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def set_global_seed(seed: int):
    """random / numpy / hash seed ê³ ì •"""
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¸ì íŒŒì„œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_args():
    p = argparse.ArgumentParser(description="DenseClus í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    p.add_argument("--data_path", default='./data/flat-training.csv', help="CSV ë°ì´í„° ê²½ë¡œ")
    p.add_argument("--save_name", default='hp_config', help="ì €ì¥ íŒŒì¼ ì´ë¦„ (í™•ì¥ì ì œì™¸)")
    p.add_argument("--method", type=str, 
                   choices=["intersection", "union", "contrast", "intersection_union_mapper", "ensemble"],
                   default='intersection_union_mapper')
    p.add_argument("--sample", type=int, default=None, help="íŠœë‹ìš© ìƒ˜í”Œ ìˆ˜")
    p.add_argument("--dropna", action="store_true", help="ê²°ì¸¡ ì»¬ëŸ¼ ì œê±° ì—¬ë¶€")
    p.add_argument("--seed", type=int, default=42, help="ëœë¤ ì‹œë“œ")
    p.add_argument("--max_clusters", type=int, default=10, help='ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜')
    return p.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë”© & ìƒ˜í”Œë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def read_data(path: str, sample: int, dropna: bool, seed: int):
    set_global_seed(seed)  # ìƒ˜í”Œë§ê¹Œì§€ ì‹œë“œ ê³ ì •
    df = pd.read_csv(path)
    if dropna:
        df = df.dropna(axis=1)
    if sample is not None and sample < len(df):
        df = df.sample(sample, random_state=seed)
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í‰ê°€ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def evaluate(method: str, umap_params: dict, hdbscan_params: dict, data: pd.DataFrame, seed: int):
    set_global_seed(seed)
    clf = DenseClus(
        random_state=seed,
        umap_combine_method=method,
        umap_params=umap_params,
        hdbscan_params=hdbscan_params,
    )
    clf.fit(data)
    labels = clf.labels_
    coverage = (labels >= 0).mean()  # êµ°ì§‘ì— ì†í•œ ë¹„ìœ¨
    dbcv = clf.hdbscan_.relative_validity_
    n_cluster = len(np.unique(labels[labels >= 0]))

    return coverage, dbcv, n_cluster

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    args = get_args()
    set_global_seed(args.seed)

    os.makedirs("results", exist_ok=True)
    os.makedirs("yaml", exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_prefix = f"{args.save_name}_{timestamp}"

    # íŒŒì¼ ì €ì¥ ê²½ë¡œ
    log_path = os.path.join("results", f"{save_prefix}.log")
    yaml_path = os.path.join("yaml", f"{save_prefix}.yaml")
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(message)s",
        handlers=[
            logging.FileHandler(log_path, encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )
    logger = logging.getLogger(__name__)

    # ë°ì´í„° ì¤€ë¹„
    df = read_data(args.data_path, args.sample, args.dropna, args.seed)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
    umap_grid = [
        {
            "categorical": {"n_neighbors": n_cat, "min_dist": m_cat},
            "numerical":   {"n_neighbors": n_num, "min_dist": m_num},
            "combined":    {"n_neighbors": n_com, "min_dist": m_com},
        }
        for n_cat, m_cat, n_num, m_num, n_com, m_com in product(
            [15, 30],
            [0.0, 0.2],
            [20, 40],
            [0.0, 0.2],
            [5, 10],
            [0.0, 0.2],
        )
    ]

    hdbscan_grid = [
        {"min_samples": ms, "min_cluster_size": mcs, "gen_min_span_tree": True}
        for ms, mcs in product([50, 100], [500, 1000, 2000])
    ]

    total_iter = len(umap_grid) * len(hdbscan_grid)
    pbar = tqdm(total=total_iter, desc="Grid Search", ncols=110, colour="cyan")

    best_score = float("-inf")
    best_params = None

    for u_params in umap_grid:
        for h_params in hdbscan_grid:
            coverage, dbcv, n_clusters = evaluate(args.method, u_params, h_params, df, args.seed)

            msg = f"n_clusters: {n_clusters}"
            logger.info(msg)
            pbar.write("\n " + msg)

            # í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ 10ì„ ë„˜ì–´ê°€ë©´ ë‹¤ìŒ ë£¨í”„ë¡œ ì§„í–‰
            if n_clusters > args.max_clusters:
                logger.info("í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ 10ì„ ì´ˆê³¼í•˜ë¯€ë¡œ ë‹¤ìŒ ë£¨í”„ë¡œ ë„˜ê¹ë‹ˆë‹¤.")
                continue
            score = coverage * dbcv

            if score > best_score:
                best_score = score

                best_params = {
                    "n_samples": args.sample,
                    "dropna": args.dropna,
                    "method": args.method,
                    "n_clusters": n_clusters,
                    "umap_params": u_params,
                    "hdbscan_params": h_params }

                with open(yaml_path, "w", encoding="utf-8") as f:
                    yaml.dump(best_params, f, sort_keys=False, allow_unicode=True, indent=4)

                best_msg = (
                    f"ğŸ“ˆ New best â†’ score={best_score:.4f} | cov={coverage:.6f}, dbcv={dbcv:.6f}" )
                logger.info(best_msg)
                pbar.write("\n" + best_msg)

            pbar.update(1)

    pbar.close()

    logger.info("âœ… íŠœë‹ ì™„ë£Œ!")
    logger.info(f"YAML saved to: {yaml_path}")
    logger.info(f"Log saved to : {log_path}")
    logger.info(f"Best score  : {best_score}")
    logger.info("Best params :\n" + yaml.safe_dump(best_params, sort_keys=False))
